{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3014a4d0-9487-4f8f-8c79-407057549ec8",
   "metadata": {},
   "source": [
    "# Used Car Price Analysis\n",
    "\n",
    "## Introduction\n",
    "The goal of this project is to analyze factors that make a car more or less expensive and provide recommendations to a used car dealership. We will follow the CRISP-DM framework for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f20ec-ee87-4839-a445-adc878961866",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "In this section, we will perform an initial exploration of the dataset to understand its structure, characteristics, and any issues that need to be addressed.\n",
    "\n",
    "### Load the Dataset\n",
    "We will start by loading the dataset from the CSV file into a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88608a7-e94b-4774-a405-9a54da5e1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Important libraries \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import scipy.stats as stats\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d752c5d-b7b7-47e7-b311-1dc74cbe9db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "data = pd.read_csv('data/vehicles.csv', encoding='utf-8', na_values=['', 'NA', 'NaN'], keep_default_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99180d44-0f85-423c-84bc-09e2a1899c6c",
   "metadata": {},
   "source": [
    "#### Initial Inspection\n",
    "\n",
    "We will inspect the first few rows of the dataset to get an overview of its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313822a-d101-42c3-b3de-b5ac9f220e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the last few rows of the dataset\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80223dbe-c0cf-44a1-ad21-b4205403e87b",
   "metadata": {},
   "source": [
    "#### Data Types and Summary Statistics\n",
    "\n",
    "We will check the data types of each column and generate summary statistics to understand the distribution of numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b03d85-63b4-41df-945e-2ad01174f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types of each column\n",
    "data.info()\n",
    "\n",
    "# Generate summary statistics for numerical features\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b4f5e-69dc-49f7-bd09-8362e5a6f9a2",
   "metadata": {},
   "source": [
    "#### Missing Values Analysis\n",
    "\n",
    "We will identify and quantify missing values in each column to understand the extent of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c2c92-2bde-42b8-b9a0-610b6a67d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values_summary = data.isnull().sum()\n",
    "missing_values_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a97ac-51b8-4b8a-989a-de4b2c9bc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will perform initial visualizations and analyses to generate insights into the data.\n",
    "\n",
    "# Ignore specific warning\n",
    "warnings.filterwarnings(\"ignore\", message=\".*use_inf_as_na option is deprecated.*\")\n",
    "\n",
    "# Distribution of car prices\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['price'], bins=50, kde=True)\n",
    "plt.title('Distribution of Car Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Price vs. Year\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='year', y='price', data=data)\n",
    "plt.title('Price vs. Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4fafe-82db-4fc5-a706-e842db65636e",
   "metadata": {},
   "source": [
    "#### Summary of Initial Findings\n",
    "\n",
    "- **Data Structure:** The dataset contains various features related to used cars, such as price, year, manufacturer, model, condition, and mileage.\n",
    "\n",
    "- **Missing Values:** Several columns have missing values that will need to be addressed in the data preparation phase.\n",
    "\n",
    "- **Initial Insights:** Visualizations suggest that car prices are influenced by the carâ€™s year and possibly other features.\n",
    "\n",
    "This initial understanding of the data will guide the data preparation and modeling steps to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf9c53-345d-4352-9ff7-2a1e90a5a07d",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "In this section, we will clean the data by handling missing values, removing duplicates, and transforming the data into a suitable format for analysis and modeling.\n",
    "\n",
    "### Handle Missing Values\n",
    "We will start by deciding on a strategy to handle missing values in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebec547-c1dd-47ef-812a-65d2cfb130b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the summary of missing values\n",
    "missing_values_summary = data.isnull().sum()\n",
    "\n",
    "# Drop rows with too many missing values\n",
    "threshold = 5  # Allow up to 5 missing values per row\n",
    "data_cleaned = data.dropna(thresh=len(data.columns) - threshold).copy()\n",
    "\n",
    "# Fill missing values where appropriate using .loc to avoid SettingWithCopyWarning\n",
    "data_cleaned.loc[:, 'year'] = data_cleaned['year'].fillna(data_cleaned['year'].median())\n",
    "data_cleaned.loc[:, 'odometer'] = data_cleaned['odometer'].fillna(data_cleaned['odometer'].median())\n",
    "data_cleaned.loc[:, 'condition'] = data_cleaned['condition'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'cylinders'] = data_cleaned['cylinders'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'fuel'] = data_cleaned['fuel'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'title_status'] = data_cleaned['title_status'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'transmission'] = data_cleaned['transmission'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'drive'] = data_cleaned['drive'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'size'] = data_cleaned['size'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'type'] = data_cleaned['type'].fillna('unknown')\n",
    "data_cleaned.loc[:, 'paint_color'] = data_cleaned['paint_color'].fillna('unknown')\n",
    "\n",
    "# Verify the cleaning process\n",
    "data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7af3e-7f47-4944-bd67-0e974c98fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping VIN as it has many missing values and it is not crucial for analysis\n",
    "data_cleaned = data_cleaned.drop(columns=['VIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab008f-c7ff-4d08-b80a-cfb881a978ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For manufacturer and model, we could drop rows with missing values or fill them with a placeholder\n",
    "data_cleaned = data_cleaned.dropna(subset=['manufacturer', 'model'])\n",
    "\n",
    "# Verifying dataframe again\n",
    "data_cleaned.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e09dd-2e4a-4a2d-8994-f08b59dadca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = data_cleaned.duplicated().sum()\n",
    "print(f'Number of duplicate rows: {duplicates}')\n",
    "\n",
    "# Remove duplicates\n",
    "data_cleaned = data_cleaned.drop_duplicates()\n",
    "\n",
    "# Verify removal of duplicates\n",
    "data_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b46a8c-3de3-48e6-a205-2bcbdb91cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data Types\n",
    "# We will ensure all columns have appropriate data types for analysis.\n",
    "\n",
    "data_cleaned['year'] = data_cleaned['year'].astype(int)\n",
    "data_cleaned['price'] = data_cleaned['price'].astype(float)\n",
    "data_cleaned['odometer'] = data_cleaned['odometer'].astype(float)\n",
    "\n",
    "# Verify data types\n",
    "data_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f4485-3018-4ba2-a9cc-6ea6e56e77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 'car_age' feature from the 'year' column\n",
    "data_cleaned['car_age'] = 2024 - data_cleaned['year']\n",
    "\n",
    "# Verify the new feature\n",
    "data_cleaned[['year', 'car_age']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9128c-03ae-4f5f-9ac5-e8d4123e9a5f",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "- The DataFrame now has 372,156 entries with most columns having no missing values.\n",
    "- Manufacturer and model columns have been cleaned by dropping rows with missing values.\n",
    "- The VIN column has been dropped due to a high number of missing values.\n",
    "- Created new feature such as **car_age** to enhance the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be4f742-8f9d-47a0-9325-9633bcad74dd",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we will perform EDA to understand the distribution of key variables, identify relationships between variables, and detect outliers and anomalies.\n",
    "\n",
    "### Handling Outliers\n",
    "\n",
    "From the initial analysis of the `price` column, we found that a few outliers are significantly skewing the analysis. Removing these outliers will provide a clearer view of the data. We will identify and remove these outliers before proceeding with EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb064baa-6116-4eb9-aa99-584a9531cf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate IQR to identify outliers\n",
    "Q1 = data_cleaned['price'].quantile(0.25)\n",
    "Q3 = data_cleaned['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier boundaries\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers\n",
    "df = data_cleaned[(data_cleaned['price'] >= lower_bound) & (data_cleaned['price'] <= upper_bound)]\n",
    "\n",
    "# Verify the data after removing outliers\n",
    "print(f\"Original dataset size: {data_cleaned.shape}\")\n",
    "print(f\"Dataset size after removing outliers: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f6d20a-7b4f-4dae-af27-0211da22d5e9",
   "metadata": {},
   "source": [
    "#### Distribution of Numerical Variables\n",
    "\n",
    "We will start by visualizing the distribution of numerical variables such as price, year, and odometer using Plotly on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadae6b3-3c39-4f67-9f04-703d339b6fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x='price', nbins=50, title='Distribution of Car Prices')\n",
    "fig.update_layout(xaxis_title='Price', yaxis_title='Frequency')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dd466-3cf2-41af-8a77-3a88d2c9a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of car year\n",
    "fig = px.histogram(df, x='year', nbins=50, title='Distribution of Car Year')\n",
    "fig.update_layout(xaxis_title='Year', yaxis_title='Frequency')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12fd3e6-5c08-49bc-81d7-0448a3117d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of odometer readings\n",
    "fig = px.histogram(df, x='odometer', nbins=50, title='Distribution of Odometer Readings')\n",
    "fig.update_layout(xaxis_title='Odometer', yaxis_title='Frequency')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1ac7c-bf7f-4f63-b769-389cea2ee92b",
   "metadata": {},
   "source": [
    "#### Relationships Between Variables\n",
    "\n",
    "We will explore relationships between variables using scatter plots and box plots in Plotly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0475717f-99e5-4f76-b7d1-7b90d071160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price vs. Year\n",
    "fig = px.scatter(df, x='year', y='price', title='Price vs. Year')\n",
    "fig.update_layout(xaxis_title='Year', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eaa929-6bb5-45b4-b67a-5ba98b331bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price vs. car age\n",
    "fig = px.scatter(df, x='car_age', y='price', title='Price vs. car_age')\n",
    "fig.update_layout(xaxis_title='car_age', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff4d8fe-a5dc-46e0-9da5-128a92db4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price vs. Odometer\n",
    "fig = px.scatter(df, x='odometer', y='price', title='Price vs. Odometer')\n",
    "fig.update_layout(xaxis_title='Odometer', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b046d344-6fee-45c1-964a-2f68a006959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by Manufacturer\n",
    "fig = px.box(df, x='manufacturer', y='price', title='Price by Manufacturer')\n",
    "fig.update_layout(xaxis_title='Manufacturer', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a14bc-0c91-474f-8c00-02e26da2c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns for correlation matrix\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Create and visualize the correlation matrix\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=correlation_matrix.values,\n",
    "    x=list(correlation_matrix.columns),\n",
    "    y=list(correlation_matrix.index),\n",
    "    annotation_text=correlation_matrix.round(2).values,\n",
    "    colorscale='Viridis'\n",
    ")\n",
    "fig.update_layout(title='Correlation Matrix', xaxis_title='Variables', yaxis_title='Variables')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a9af2f-2d51-4928-8d7d-b64b9bc5938a",
   "metadata": {},
   "source": [
    "#### Categorical Variable Analysis\n",
    "\n",
    "We will analyze the distribution of categorical variables and their relationship with the target variable (price).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552b3d4-c036-4425-95a2-dde4d1b9dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by Condition\n",
    "fig = px.box(df, x='condition', y='price', title='Price by Condition')\n",
    "fig.update_layout(xaxis_title='Condition', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be818c97-fc20-4dbe-996e-caa6a99d66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by Fuel Type\n",
    "fig = px.box(df, x='fuel', y='price', title='Price by Fuel Type')\n",
    "fig.update_layout(xaxis_title='Fuel Type', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0183d5-7871-4fdd-9bad-13be22a89999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by Transmission Type\n",
    "fig = px.box(df, x='transmission', y='price', title='Price by Transmission Type')\n",
    "fig.update_layout(xaxis_title='Transmission', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d705c0-f8c3-4859-8fc5-977a6c2fb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price by Drive Type\n",
    "fig = px.box(df, x='drive', y='price', title='Price by Drive Type')\n",
    "fig.update_layout(xaxis_title='Drive Type', yaxis_title='Price')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e53703-7942-4503-b85e-2d42a636a1cc",
   "metadata": {},
   "source": [
    "#### Summary of EDA\n",
    "\n",
    "- **Distribution Analysis:** Visualized the distribution of key numerical variables (price, year, odometer). Removing outliers provided a clearer view of the price distribution.\n",
    "\n",
    "- **Relationship Analysis:** Scatter plots revealed that newer cars tend to have higher prices, and cars with lower odometer readings are generally priced higher. Box plots showed significant price variation across different manufacturers.\n",
    "\n",
    "- **Correlation Matrix:** Identified relationships between numerical variables using a correlation matrix.\n",
    "\n",
    "- **Categorical Variable Analysis:** Box plots illustrated how car prices vary by condition, fuel type, transmission type, and drive type, providing insights into consumer preferences and market trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7969ba-8221-438a-aa13-6739f891cb8a",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "In this section, we will build and evaluate regression models to understand the factors that influence car prices. We will start with simple linear regression and explore more complex models. We will also use cross-validation to validate our models and perform hyperparameter tuning to optimize their performance.\n",
    "\n",
    "Before diving into the modeling, we will preprocess the data to ensure it is in a suitable format for machine learning algorithms. This preprocessing includes steps such as one-hot encoding of categorical variables, scaling numerical features, and polynomial features.\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "To prepare the data for modeling, we will perform the following preprocessing steps:\n",
    "\n",
    "1. **One-Hot Encoding**: Convert categorical variables into a format that can be used by machine learning algorithms.\n",
    "2. **Scaling**: Standardize numerical features to ensure they have a mean of 0 and a standard deviation of 1.\n",
    "3. **Train-Test Split**: Split the data into training and testing sets.\n",
    "4. **Transformations**: Apply any necessary transformations to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7eb5e59-6a0d-4eb3-8a62-ffc58fa90d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['year', 'odometer', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color', 'state']\n",
    "target = 'price'\n",
    "\n",
    "# Select the features and target\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60596fa0-d422-4832-b73b-d703e81ebbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_features = ['year', 'odometer']\n",
    "categorical_features = [col for col in features if col not in numerical_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060ce46-8c33-4c98-bbc9-6576f144cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c1a92-3c00-4498-a1e7-e8a8552de168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column transformer that applies the appropriate transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbffab-4533-442d-b087-88d9df010093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729728ac-7aee-4959-957e-5281e09d6ab8",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression\n",
    "\n",
    "We will build and evaluate a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b220a1-d54d-4db3-9caf-a2121623bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing and modeling pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline\n",
    "\n",
    "# Fit the linear regression model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "print(f'R-squared (R^2): {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c363e4ea-e886-484d-9102-18d87bf002da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# Plot residuals vs. fitted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Residuals vs. Fitted Values')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a2274-1f03-46b2-a49c-86e904699db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plot of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55d6b5-9217-4119-b8b3-e5954d83a7c0",
   "metadata": {},
   "source": [
    "### Insights from Residual Analysis\n",
    "\n",
    "#### Residuals vs. Fitted Values Plot\n",
    "- Funnel shape indicates heteroscedasticity, violating the constant variance assumption.\n",
    "- Clear trend suggests missing key variables or need for a non-linear model.\n",
    "\n",
    "#### Q-Q Plot of Residuals\n",
    "- Deviation from the reference line, especially at the tails, indicates non-normality.\n",
    "- Suggests presence of outliers or heavy-tailed data, affecting model reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b5b49-3b7a-43ff-87be-d5b9b0d90966",
   "metadata": {},
   "source": [
    "### Non Linear Regression\n",
    "In this section, we will incorporate polynomial features of degree 3, use Ridge regression for feature selection, apply GridSearchCV for hyperparameter tuning, and then evaluate the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab8897-bab7-4126-9e19-42b75a20b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['year', 'odometer', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'size', 'type', 'paint_color', 'state']\n",
    "target = 'price'\n",
    "\n",
    "# Select the features and target\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Define the preprocessing steps for numerical and categorical data\n",
    "numerical_features = ['year', 'odometer']\n",
    "categorical_features = [col for col in features if col not in numerical_features]\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Create a column transformer that applies the appropriate transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8d73f-5e2f-40df-9b5f-c409abac1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Ridge regression model\n",
    "ridge = Ridge(solver='auto')  # Using 'auto' solver for simplicity\n",
    "\n",
    "# Create a pipeline with preprocessing and Ridge regression\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('ridge', ridge)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55e514-7a53-423a-97be-7a0027999a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'ridge__alpha': np.logspace(-3, 2, 20) # Regularization strengths from 0.001 to 1000\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599c735-11f5-4be8-9485-5037ca692090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters from GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters: {best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2c0e5-c724-4fef-8264-e028d05e260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "print(f'Cross-validated R^2 scores: {cv_scores}')\n",
    "print(f'Mean cross-validated R^2 score: {cv_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c4ccfb-8a3d-4680-a11b-f703a521dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the fitted preprocessor and extract feature names\n",
    "fitted_preprocessor = grid_search.best_estimator_.named_steps['preprocessor']\n",
    "fitted_numerical_transformer = fitted_preprocessor.named_transformers_['num'].named_steps['poly']\n",
    "fitted_categorical_transformer = fitted_preprocessor.named_transformers_['cat']\n",
    "\n",
    "# Extract feature names after fitting the preprocessor\n",
    "poly_feature_names = fitted_numerical_transformer.get_feature_names_out(numerical_features)\n",
    "cat_feature_names = fitted_categorical_transformer.get_feature_names_out(categorical_features)\n",
    "feature_names = np.concatenate([poly_feature_names, cat_feature_names])\n",
    "\n",
    "# Extract the best model and its coefficients\n",
    "best_model = grid_search.best_estimator_.named_steps['ridge']\n",
    "coefs = best_model.coef_\n",
    "\n",
    "# Create a DataFrame for the coefficients\n",
    "coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd75c0-1d92-432b-9bd0-a39cee7d97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef75de-a6b2-4f98-87e4-16f70bb70f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the most important features\n",
    "important_features = coef_df.sort_values(by='Coefficient', ascending=False).head(10)\n",
    "print('Top 10 Important Features:')\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52d8a6-0202-461e-b0fe-6a071fa92794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the coefficients of the most important features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=important_features)\n",
    "plt.title('Top 10 Important Features')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594d678-a0fc-4ab2-b671-d84b48b04f2c",
   "metadata": {},
   "source": [
    "## Recommendations:\n",
    "Based on the analysis, the following factors are key in determining car prices:\n",
    "\n",
    "- Car Age: Newer cars tend to be priced higher.\n",
    "- Odometer Reading: Cars with lower mileage are generally more expensive.\n",
    "- Manufacturer and Model: Certain manufacturers and models, such as luxury and sports cars, have higher prices.\n",
    "- Condition: Cars in better condition (e.g., â€˜like newâ€™, â€˜excellentâ€™) are valued more.\n",
    "- Fuel Type: Gasoline and electric cars are generally priced higher than diesel and hybrid cars.\n",
    "- Transmission and Drive Type: Manual transmission and all-wheel drive cars tend to be priced higher.\n",
    "\n",
    "To fine-tune their inventory, used car dealerships should focus on acquiring newer cars with lower mileage, maintaining a diverse range of popular manufacturers and models, and ensuring that the cars are in good condition. Additionally, understanding consumer preferences for fuel type and transmission can help in pricing and marketing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef13bd-ff0a-46bb-a509-f93a9e2e6ce1",
   "metadata": {},
   "source": [
    "## Future Analysis\n",
    "\n",
    "Future analysis can provide deeper insights for the dealership. Detailed brand and model analysis can identify the most profitable models. Investigating geographic location impacts can reveal regional pricing trends. Analyzing seasonal trends will help plan inventory around peak buying times. Understanding consumer preferences through additional data sources can guide stock decisions. Implementing advanced machine learning models like Random Forest and Neural Networks can improve price prediction accuracy. A longitudinal study on depreciation rates will highlight cars that retain value better. Incorporating external economic indicators, such as fuel prices and interest rates, provides broader pricing context. Customer segmentation using clustering techniques enables targeted marketing. Sentiment analysis from reviews offers qualitative insights into customer satisfaction. Finally, predictive maintenance and warranty analysis can manage warranties and inform customers about future costs, enhancing trust and satisfaction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
